{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd & 4th Exercise Notebook: Example Data Mining pipeline & Introduction to Sklearn \n",
    "\n",
    "#### About this Exercise\n",
    "This is a comprehensive exercise that touches on a lot of the important steps in the data mining pipeline ‚Äî from data preprocessing and feature engineering to model training and evaluation. It will give you hands-on experience applying the steps we've covered so far.\n",
    "\n",
    "üí° Mastering this exercise will help you a lot in preparing for the final exam.\n",
    "\n",
    "‚ùóÔ∏èDon't worry if you can't solve everything right away ‚Äî data science is as much about iteration as it is about intuition. Take your time, stay curious, and most importantly: don‚Äôt give up.\n",
    "\n",
    "üö´ Please avoid using ChatGPT or other AI assistants to solve the tasks. Solving the problems yourself will help you internalize the concepts more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context:\n",
    "In the last sessions, you have learned to setup conda environment, program with numpy, and pandas. Now, it is time for more fun with a real data modelling pipeline.\n",
    "\n",
    "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
    "\n",
    "### VARIABLE DESCRIPTIONS\n",
    "- Pclass Passenger Class (1 = 1'st; 2 = 2nd; 3 = 3rd)\n",
    "- survival Survival (0 = No; 1 = Yes)\n",
    "- name Name\n",
    "- sex Sex\n",
    "- age Age\n",
    "- sibsp Number of Siblings/Spouses Aboard\n",
    "- parch Number of Parents/Children Aboard\n",
    "- ticket Ticket Number\n",
    "- fare Passenger Fare (British pound)\n",
    "- cabin Cabin\n",
    "- embarked Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- boat Lifeboat\n",
    "- body Body Identification Number\n",
    "- home.dest Home/Destination\n",
    "\n",
    "### Goal:\n",
    "Build a modelling Pipeline, to engineer the features in the data set and predict who is more likely to Survive the catastrophe.\n",
    "\n",
    "Follow the Jupyter notebook below, and solve the tasks marked as ‚úÖ Task for students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to visualise all the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed to ensure reproducibility\n",
    "random_seed = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>?</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>135</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "      age  sibsp  parch  ticket      fare    cabin embarked boat body  \\\n",
       "0      29      0      0   24160  211.3375       B5        S    2    ?   \n",
       "1  0.9167      1      2  113781    151.55  C22 C26        S   11    ?   \n",
       "2       2      1      2  113781    151.55  C22 C26        S    ?    ?   \n",
       "3      30      1      2  113781    151.55  C22 C26        S    ?  135   \n",
       "4      25      1      2  113781    151.55  C22 C26        S    ?    ?   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data - it is available open source and online\n",
    "data = pd.read_csv('https://www.openml.org/data/get_csv/16826755/phpMYEkMl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass       0.0\n",
      "survived     0.0\n",
      "name         0.0\n",
      "sex          0.0\n",
      "age          0.0\n",
      "sibsp        0.0\n",
      "parch        0.0\n",
      "ticket       0.0\n",
      "fare         0.0\n",
      "cabin        0.0\n",
      "embarked     0.0\n",
      "boat         0.0\n",
      "body         0.0\n",
      "home.dest    0.0\n",
      "dtype: float64\n",
      "pclass        int64\n",
      "survived      int64\n",
      "name         object\n",
      "sex          object\n",
      "age          object\n",
      "sibsp         int64\n",
      "parch         int64\n",
      "ticket       object\n",
      "fare         object\n",
      "cabin        object\n",
      "embarked     object\n",
      "boat         object\n",
      "body         object\n",
      "home.dest    object\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   pclass     1309 non-null   int64 \n",
      " 1   survived   1309 non-null   int64 \n",
      " 2   name       1309 non-null   object\n",
      " 3   sex        1309 non-null   object\n",
      " 4   age        1309 non-null   object\n",
      " 5   sibsp      1309 non-null   int64 \n",
      " 6   parch      1309 non-null   int64 \n",
      " 7   ticket     1309 non-null   object\n",
      " 8   fare       1309 non-null   object\n",
      " 9   cabin      1309 non-null   object\n",
      " 10  embarked   1309 non-null   object\n",
      " 11  boat       1309 non-null   object\n",
      " 12  body       1309 non-null   object\n",
      " 13  home.dest  1309 non-null   object\n",
      "dtypes: int64(4), object(10)\n",
      "memory usage: 143.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Task for students: check the percentage of NaN and the data type of each column\n",
    "# add your code here\n",
    "print((data.isnull().sum()/len(data)*100))\n",
    "print(data.dtypes )\n",
    "#or\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass          0\n",
       "survived        0\n",
       "name            0\n",
       "sex             0\n",
       "age           263\n",
       "sibsp           0\n",
       "parch           0\n",
       "ticket          0\n",
       "fare            1\n",
       "cabin        1014\n",
       "embarked        2\n",
       "boat          823\n",
       "body         1188\n",
       "home.dest     564\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚úÖ Task for students: replace question marks by NaN values, why?\n",
    "'''\n",
    "pandas and most data analysis tools do not recognize ? as a missing value by default. They only recognize NaN (Not a Number) or None as missing.\n",
    "If you leave ? in your data:\n",
    "- pandas will treat it as a regular string, not as a missing value.\n",
    "- Functions like .isnull(), .dropna(), or .fillna() will not work on those cells.\n",
    "- This can lead to incorrect analysis, statistics, or model training.'''\n",
    "# add your code here\n",
    "import numpy as np\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "#or\n",
    "#data = data.replace('?', np.nan)\n",
    "\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: name\n",
      "Number of unique values: 1307\n",
      "Unique values: ['Allen, Miss. Elisabeth Walton' 'Allison, Master. Hudson Trevor'\n",
      " 'Allison, Miss. Helen Loraine' ... 'Zakarian, Mr. Mapriededer'\n",
      " 'Zakarian, Mr. Ortin' 'Zimmerman, Mr. Leo']\n",
      "----------------------------------------\n",
      "Column: sex\n",
      "Number of unique values: 2\n",
      "Unique values: ['female' 'male']\n",
      "----------------------------------------\n",
      "Column: age\n",
      "Number of unique values: 98\n",
      "Unique values: ['29' '0.9167' '2' '30' '25' '48' '63' '39' '53' '71' '47' '18' '24' '26'\n",
      " '80' nan '50' '32' '36' '37' '42' '19' '35' '28' '45' '40' '58' '22' '41'\n",
      " '44' '59' '60' '33' '17' '11' '14' '49' '76' '46' '27' '64' '55' '70'\n",
      " '38' '51' '31' '4' '54' '23' '43' '52' '16' '32.5' '21' '15' '65' '28.5'\n",
      " '45.5' '56' '13' '61' '34' '6' '57' '62' '67' '1' '12' '20' '0.8333' '8'\n",
      " '0.6667' '7' '3' '36.5' '18.5' '5' '66' '9' '0.75' '70.5' '22.5' '0.3333'\n",
      " '0.1667' '40.5' '10' '23.5' '34.5' '20.5' '30.5' '55.5' '38.5' '14.5'\n",
      " '24.5' '60.5' '74' '0.4167' '11.5' '26.5']\n",
      "----------------------------------------\n",
      "Column: ticket\n",
      "Number of unique values: 929\n",
      "Unique values: ['24160' '113781' '19952' '13502' '112050' '11769' 'PC 17609' 'PC 17757'\n",
      " 'PC 17477' '19877' '27042' 'PC 17318' 'PC 17558' '11813' '13050' '11751'\n",
      " '111369' 'PC 17483' '13905' '11967' 'PC 17760' '110564' '113784' '112277'\n",
      " '36928' '113783' '110489' 'PC 17608' '113505' '111427' '113054'\n",
      " 'PC 17591' '112379' 'PC 17610' '16966' '113050' '113798' 'PC 17476'\n",
      " 'PC 17606' 'PC 17755' '695' '113059' '113760' '19924' '17770'\n",
      " 'W.E.P. 5734' '113806' '110152' 'PC 17594' '112051' '13508' '110465'\n",
      " '5727' 'PC 17756' '11770' '113791' 'WE/P 5735' '112901' 'PC 17599'\n",
      " '113055' '113804' 'F.C. 12750' '17474' '33638' 'PC 17761' '11755'\n",
      " 'PC 17485' 'PC 17580' '11767' '36947' 'PC 17531' 'PC 17598' '17421'\n",
      " 'PC 17474' '113051' '19950' '113778' 'PC 17611' '17765' '13568' '13567'\n",
      " '112058' '113803' '111320' '113503' '112378' 'PC 17593' '17453'\n",
      " 'PC 17754' '113780' '112053' 'PC 17582' 'PC 17759' '11765' 'PC 17572'\n",
      " '113796' '36973' '112059' '16988' '12749' '113038' '17463' '680' '111361'\n",
      " '113789' '111426' '19943' 'PC 17600' '113572' 'PC 17595' '694' '113044'\n",
      " '11771' '17464' '11753' '113028' '17465' 'PC 17612' '17475' '112377'\n",
      " 'PC 17592' '113501' '113801' 'PC 17569' '110469' '11774' '113773'\n",
      " 'PC 17482' 'PC 17473' 'PC 17604' '13509' '19928' '13236' '113787'\n",
      " 'PC 17596' '35273' '11752' '693' 'PC 17758' 'F.C. 12998' '113509'\n",
      " 'PC 17562' '112052' '113043' '113776' '113786' '19972' 'PC 17607'\n",
      " 'PC 17590' '111428' '113767' 'PC 17613' 'PC 17585' '13049' 'PC 17603'\n",
      " '113790' '19988' '111163' '113794' 'PC 17475' '13507' '13213' '113788'\n",
      " '113792' '17764' '13695' '113056' '21228' '13214' '113514' '11778'\n",
      " 'PC 17605' '36963' '17466' '110413' '19996' '2543' 'PC 17601' '111240'\n",
      " '36967' '110813' '113800' '35281' '113795' 'PC 17597' '113510' '19947'\n",
      " '113807' 'P/PP 3381' '248744' '231945' 'C.A. 34050' '226875' '244346'\n",
      " '29108' 'C.A. 31030' '28551' 'C.A./SOTON 34068' 'S.O.P. 1166' '2908'\n",
      " '244358' '230136' '248698' '28404' '28425' '237670' '211535' '220367'\n",
      " '248733' '29750' '236853' '27849' '234686' '244310' '236852' '248738'\n",
      " 'F.C.C. 13528' '239853' '28424' '244252' '248731' 'SC/AH 29037' '237789'\n",
      " '2003' 'W./C. 14263' '248740' '28034' 'C.A. 31921' 'W./C. 14266' '237249'\n",
      " 'F.C.C. 13534' '29107' 'C.A. 33112' 'S.O.C. 14879' '237668' '244360'\n",
      " 'SC/PARIS 2167' 'C.A. 31029' '231919' '28403' '28220' 'SC/PARIS 2149'\n",
      " 'SC/PARIS 2148' '29751' '236854' '236171' '2926' 'C.A. 15185' '229236'\n",
      " '239854' '237671' '239865' '28664' '243880' '31028' 'C.A. 30769' '28133'\n",
      " '28134' '248726' '233866' '12233' '250646' '250647' '250653' '250649'\n",
      " '248746' '248727' 'S.W./PP 752' 'W/C 14208' 'F.C.C. 13529' '220845'\n",
      " '248706' '250650' '29105' '29104' '242963' '250643' '26707' '237798'\n",
      " '24065' 'SCO/W 1585' 'SO/C 14885' '243847' '237565' 'C.A. 33111'\n",
      " 'SC/AH Basle 541' '244367' '226593' '233734' '223596' '219533' '239855'\n",
      " 'C.A. 18723' '250651' '240261' 'SC/Paris 2123' 'SC 1748' 'C.A. 34260'\n",
      " 'SC/Paris 2163' 'C.A. 29566' '235509' 'SC/AH 3085' 'S.O./P.P. 3' '237735'\n",
      " 'S.C./PARIS 2079' 'SC/A.3 2861' '28228' '239059' '237216' '233478'\n",
      " '250644' 'SW/PP 751' '248723' '234360' 'C.A. 24580' '211536' '29011'\n",
      " '250655' '240276' '237736' '230080' '244368' '218629' 'SC/PARIS 2166'\n",
      " 'C.A. 29395' '28213' 'W./C. 14260' 'SC/PARIS 2146' '244278'\n",
      " 'SC/PARIS 2147' 'SC 14888' '230433' '28665' 'SC/PARIS 2131' '237393'\n",
      " 'S.O./P.P. 2' '234604' 'C.A. 34644' 'SC/PARIS 2168' '26360' 'C.A. 17248'\n",
      " '31027' '230434' 'SC/PARIS 2133' '29106' 'W./C. 14258' '28004'\n",
      " 'C.A. 31026' '248659' '244361' '250652' '250648' '237442' '234818'\n",
      " '28206' '31418' 'C.A. 29178' '237734' 'F.C.C. 13540' '248734'\n",
      " 'F.C.C. 13531' '233639' '240929' '34218' '11668' '28221' 'CA 31352'\n",
      " '28666' '239856' 'C.A. 33595' '27267' '228414' '29103' 'C.A. 34651'\n",
      " 'C.A. 24579' 'SC/PARIS 2159' '244270' '244373' '220844' '248747'\n",
      " 'C.A. 5547' 'C.A. 2673' '348125' '348122' 'SOTON/O2 3101284' '2657'\n",
      " 'C 7076' '341826' '7546' '392091' '2699' '3474' 'SOTON/O2 3101287'\n",
      " 'SOTON/O.Q. 3101311' 'SOTON/O.Q. 3101312' '373450' '2223' 'C 4001'\n",
      " '350046' '347082' '3101281' '347091' '350043' '347075' '347466' '349202'\n",
      " '349237' '349911' 'SOTON/O.Q. 3101310' '347077' '350054' '2696' '2692'\n",
      " 'SOTON/O.Q. 3101309' '2627' '2694' '347468' '2687' '2679' '3101278'\n",
      " '2666' 'A/4 31416' '2623' '349248' '2663' '2691' '330844' '324669'\n",
      " '323951' '347068' 'PP 4348' '2622' '2648' '1601' '312992' '347090'\n",
      " '349224' '2678' '2664' '364848' '364849' '54636' '334914' '347471' '3460'\n",
      " 'A/5 21171' '350045' '364512' '329944' '330920' '365222' '330963'\n",
      " '315087' '315084' '315091' '315089' '315093' '315086' '364846' '364858'\n",
      " 'A./5. 2152' '2689' '350042' '350409' '367231' '368364' '392095' '343275'\n",
      " 'A/5. 13032' '343276' '2680' 'SOTON/O.Q. 3101307' 'A/5 3540' '371109'\n",
      " '349210' '349209' '21332' '335097' '370373' '330972' '370369' 'A/5 3536'\n",
      " '349230' '349229' '349231' 'SOTON/OQ 392090' 'C.A. 37671' '364500'\n",
      " 'S.P. 3464' '371362' '315090' '2698' '7598' '7552' '349228' '382650'\n",
      " '382651' '347080' '349219' '349203' 'A/4 48871' 'SC/A4 23568' 'A/4 48873'\n",
      " '386525' '345572' '345774' '345778' 'C.A. 2315' '349250' '349238'\n",
      " '349225' 'A/5 21172' 'A/5 21175' '330958' '349232' '315088' '349226'\n",
      " '2686' '370376' 'A/5. 10482' '364516' '368702' 'SOTON/OQ 392083' '349241'\n",
      " '336439' 'S.O./P.P. 752' '347072' '349912' '347074' '347061' '2674'\n",
      " '2675' '2690' '2695' 'A/5 3902' '2631' 'C.A. 6212' '367232'\n",
      " 'SOTON/O.Q. 3101308' '350036' '364859' '364851' '368323' '330910'\n",
      " '365235' 'W./C. 6608' 'A/5 1478' '368573' 'SOTON/O.Q. 3101314' '36864'\n",
      " '358585' '349254' '14973' '35851' '335677' '363291' 'SOTON/O.Q. 3101263'\n",
      " 'SOTON/O.Q. 3101306' 'CA 2144' '21440' '8471' '376563' '7534' '3101276'\n",
      " '3101277' '347069' '349236' 'AQ/3. 30631' '65303' '65304'\n",
      " 'STON/O2. 3101279' '345769' '2693' '350026' '350025' '350029'\n",
      " 'W./C. 6609' '374887' '394140' '370375' '347089' '365226'\n",
      " 'STON/O2. 3101282' 'STON/O2. 3101290' '7548' '349243' '347086' '382649'\n",
      " '3101298' 'C 7075' 'STON/O2. 3101283' '370377' 'A. 2. 39186' '348121'\n",
      " '3470' '2685' '349220' 'STON/O2. 3101270' 'STON/O2. 3101271' '349201'\n",
      " '349240' '350034' 'SOTON/O.Q. 3101305' '350050' '350047' '350048' '14313'\n",
      " '65306' '3101264' '347070' '350052' '7540' '347063' '347467' '347742'\n",
      " 'LINE' '347062' 'W./C. 6607' '349204' '350417' '350408' '4136' '4137'\n",
      " 'STON/O 2. 3101286' 'STON/O 2. 3101274' '8475' '349246' '350053' '347465'\n",
      " '350060' '349256' '2700' '2682' '12460' '323592' '9234' '14312' '330911'\n",
      " '363592' '368783' '2660' '367227' '367229' '36865' '315152' '315151'\n",
      " '315153' '350405' '350404' '349253' '2654' '2624' '4135' '349217'\n",
      " 'C 7077' '7935' '7545' '347067' '347065' '2620' '4133'\n",
      " 'STON/O 2. 3101292' '2683' '370371' '345781' '347071' '347073' '349910'\n",
      " 'STON/O 2. 3101285' '330971' 'S.O./P.P. 251' 'A/5. 3336' '1222'\n",
      " 'A/5 21173' '315098' '347743' '347469' '350403' '349235' 'C.A. 42795'\n",
      " '370370' 'C 17369' 'STON/O 2. 3101275' '330924' 'AQ/4 3130' 'A/S 2816'\n",
      " 'STON/O 2. 3101268' '2677' '364850' '36866' '2655' '349213' '349257'\n",
      " '2649' '349255' '383123' '367228' '367226' '330932' '36568' '330931'\n",
      " '330923' '9232' '370372' '376566' '370368' 'SOTON/O.Q. 392087' '343095'\n",
      " 'A.5. 11206' '368703' '345501' '359306' '349233' '349211' '349207'\n",
      " '349221' '330980' '348123' '392096' 'A4. 54510' '371110' '330877'\n",
      " '364506' '372622' '312991' '2661' '2626' '374746' '35852' '382653'\n",
      " 'A./5. 3235' '367230' '347078' '349206' '2667' '2653' 'A./5. 3338'\n",
      " '349218' '2652' '365237' '349234' '2651' '3101297' '363611' '347066'\n",
      " '347470' '350410' 'SOTON/O2 3101272' 'STON/O 2. 3101289' 'A/4. 39886'\n",
      " '2697' '347081' '345364' '370365' '330979' '334912' '371060' '366713'\n",
      " '7267' '364856' '14311' '330959' '347085' '368402' '330919' 'C 17368'\n",
      " '4579' 'Fa 265302' '350407' '347464' '347079' '6563' '315085' '315096'\n",
      " '315094' '349244' '330909' '349909' '3101295' '315097' '3411' '349242'\n",
      " 'SOTON/O.Q. 3101315' '343271' '345498' 'A/5 2817' 'STON/O 2. 3101294'\n",
      " 'STON/O 2. 3101291' 'A/5 21174' '347083' '2668' '330935' '342441'\n",
      " '349245' '349212' '349215' '347076' '347087' 'SOTON/O.Q. 392078' '349227'\n",
      " '315095' '315092' '349223' '65305' '2629' '362316' '349249' '342684'\n",
      " '382652' 'STON/O 2. 3101273' '334915' '364498' 'A/5. 3337'\n",
      " 'S.C./A.4. 23567' '312993' '370129' '342712' 'A/5 3594' 'A/4. 20589'\n",
      " '383162' '2671' '2672' '2676' '367655' 'LP 1588' 'SOTON/O.Q. 3101262'\n",
      " 'CA. 2343' '7266' '343120' '3101296' '2662' 'PP 9549' '345768'\n",
      " 'A/5. 2151' '342826' '36209' '349222' '370374' '345779' '330968' '374910'\n",
      " 'SOTON/OQ 392082' '2669' '392092' '349251' 'STON/O 2. 3101280' '3101265'\n",
      " '347088' '349214' 'SOTON/OQ 392086' '315037' '384461' '335432' '348124'\n",
      " 'A.5. 18509' 'A.5. 3236' 'STON/OQ. 369943' '349208' '349239' 'CA. 2314'\n",
      " 'A/4 45380' '3701' '349205' '7553' 'STON/O 2. 3101288' '315083' '347054'\n",
      " 'SOTON/OQ 392089' 'STON/O 2. 3101269' 'SOTON/OQ 392076' '347060' '7538'\n",
      " '350035' '350033' '363294' '2625' '2621' '2681' '2684' '32302' '376564'\n",
      " 'STON/O 2. 3101293' '383121' '349216' '364499' '364511' '2673' '2641'\n",
      " '2650' '349247' '4138' '4134' 'A/5. 851' '345773' '345777' '345780'\n",
      " '345770' '345783' '345765' '345764' '345763' '2658' '350416' '350406'\n",
      " '349252' '345767' '359309' 'C.A. 49867' 'SOTON/OQ 3101316' '345775'\n",
      " '2688' '347064' '3101267' '3101266' '363272' '3410' 'S.O./P.P. 751'\n",
      " 'A/5 2466' 'SOTON/OQ 3101317' '315154' 'A/4. 34244' '345771' '2659'\n",
      " '2628' '2647' '2665' '2656' '2670' '315082']\n",
      "----------------------------------------\n",
      "Column: fare\n",
      "Number of unique values: 281\n",
      "Unique values: ['211.3375' '151.55' '26.55' '77.9583' '0' '51.4792' '49.5042' '227.525'\n",
      " '69.3' '78.85' '30' '25.925' '247.5208' '76.2917' '75.2417' '52.5542'\n",
      " '221.7792' '26' '91.0792' '135.6333' '35.5' '31' '164.8667' '262.375'\n",
      " '55' '30.5' '50.4958' '39.6' '27.7208' '134.5' '26.2875' '27.4458'\n",
      " '512.3292' '5' '47.1' '120' '61.175' '53.1' '86.5' '29.7' '136.7792' '52'\n",
      " '25.5875' '83.1583' '25.7' '71' '71.2833' '57' '81.8583' '106.425'\n",
      " '56.9292' '78.2667' '31.6792' '31.6833' '110.8833' '26.3875' '27.75'\n",
      " '263' '133.65' '49.5' '79.2' '38.5' '211.5' '59.4' '89.1042' '34.6542'\n",
      " '28.5' '153.4625' '63.3583' '55.4417' '76.7292' '42.4' '83.475' '93.5'\n",
      " '42.5' '51.8625' '50' '57.9792' '90' '30.6958' '80' '28.7125' '25.9292'\n",
      " '39.4' '45.5' '146.5208' '82.1708' '57.75' '113.275' '26.2833' '108.9'\n",
      " '25.7417' '61.9792' '66.6' '40.125' '55.9' '60' '82.2667' '32.3208'\n",
      " '79.65' '28.5375' '33.5' '34.0208' '75.25' '77.2875' '61.3792' '35' '24'\n",
      " '13' '11.5' '10.5' '12.525' '39' '29' '21' '13.5' '26.25' '36.75' '73.5'\n",
      " '31.5' '23' '32.5' '13.8583' '14.5' '33' '65' '16' '12.275' '27' '15'\n",
      " '13.7917' '12.35' '10.7083' '41.5792' '12' '12.875' '15.0458' '37.0042'\n",
      " '15.5792' '19.5' '14' '9.6875' '30.0708' '13.8625' '15.05' '12.7375'\n",
      " '15.0333' '18.75' '12.65' '15.75' '7.55' '20.25' '7.65' '7.925' '7.2292'\n",
      " '7.25' '8.05' '9.475' '9.35' '18.7875' '7.8875' '7.05' '8.3' '22.525'\n",
      " '7.8542' '31.275' '7.775' '7.7958' '7.8958' '17.8' '31.3875' '7.225'\n",
      " '14.4583' '15.85' '19.2583' '14.4542' '7.8792' '4.0125' '56.4958' '7.75'\n",
      " '15.2458' '15.5' '16.1' '7.725' '7.0458' '7.2833' '7.8208' '6.75'\n",
      " '8.6625' '7.7333' '7.4958' '7.6292' '15.9' '8.1583' '10.5167' '10.1708'\n",
      " '6.95' '14.4' '24.15' '17.4' '9.5' '20.575' '12.475' '13.9' '6.975'\n",
      " '15.1' '34.375' '7.7417' '20.525' '7.85' '46.9' '8.3625' '9.8458' '8.85'\n",
      " '19.9667' '14.1083' '6.8583' '8.9625' '12.2875' '6.45' '7.0542' '8.1125'\n",
      " '6.4958' '8.6542' '11.1333' '23.45' '9.825' '7.125' '8.4333' '7.5208'\n",
      " '13.4167' '7.8292' '7.7375' '22.025' '12.1833' '9.5875' '9.4833'\n",
      " '25.4667' '6.4375' '15.55' '7.5792' '7.1417' '23.25' '7.7875' '8.0292'\n",
      " '8.4583' '15.7417' '11.2417' '7.8' '6.2375' '9.225' '3.1708' '8.4042'\n",
      " '7.3125' '9.2167' '8.6833' '21.075' '39.6875' '8.7125' '13.775' '7'\n",
      " '22.3583' '8.1375' '29.125' '7.7208' '20.2125' '7.7292' '7.575' '69.55'\n",
      " '9.325' '21.6792' '16.7' '7.7792' '27.9' nan '9.8375' '10.4625' '8.5167'\n",
      " '9.8417' '9' '18' '7.875']\n",
      "----------------------------------------\n",
      "Column: cabin\n",
      "Number of unique values: 186\n",
      "Unique values: ['B5' 'C22 C26' 'E12' 'D7' 'A36' 'C101' nan 'C62 C64' 'B35' 'A23'\n",
      " 'B58 B60' 'D15' 'C6' 'D35' 'C148' 'C97' 'B49' 'C99' 'C52' 'T' 'A31' 'C7'\n",
      " 'C103' 'D22' 'E33' 'A21' 'B10' 'B4' 'E40' 'B38' 'E24' 'B51 B53 B55'\n",
      " 'B96 B98' 'C46' 'E31' 'E8' 'B61' 'B77' 'A9' 'C89' 'A14' 'E58' 'E49' 'E52'\n",
      " 'E45' 'B22' 'B26' 'C85' 'E17' 'B71' 'B20' 'A34' 'C86' 'A16' 'A20' 'A18'\n",
      " 'C54' 'C45' 'D20' 'A29' 'C95' 'E25' 'C111' 'C23 C25 C27' 'E36' 'D34'\n",
      " 'D40' 'B39' 'B41' 'B102' 'C123' 'E63' 'C130' 'B86' 'C92' 'A5' 'C51' 'B42'\n",
      " 'C91' 'C125' 'D10 D12' 'B82 B84' 'E50' 'D33' 'C83' 'B94' 'D49' 'D45'\n",
      " 'B69' 'B11' 'E46' 'C39' 'B18' 'D11' 'C93' 'B28' 'C49' 'B52 B54 B56' 'E60'\n",
      " 'C132' 'B37' 'D21' 'D19' 'C124' 'D17' 'B101' 'D28' 'D6' 'D9' 'B80' 'C106'\n",
      " 'B79' 'C47' 'D30' 'C90' 'E38' 'C78' 'C30' 'C118' 'D36' 'D48' 'D47' 'C105'\n",
      " 'B36' 'B30' 'D43' 'B24' 'C2' 'C65' 'B73' 'C104' 'C110' 'C50' 'B3' 'A24'\n",
      " 'A32' 'A11' 'A10' 'B57 B59 B63 B66' 'C28' 'E44' 'A26' 'A6' 'A7' 'C31'\n",
      " 'A19' 'B45' 'E34' 'B78' 'B50' 'C87' 'C116' 'C55 C57' 'D50' 'E68' 'E67'\n",
      " 'C126' 'C68' 'C70' 'C53' 'B19' 'D46' 'D37' 'D26' 'C32' 'C80' 'C82' 'C128'\n",
      " 'E39 E41' 'D' 'F4' 'D56' 'F33' 'E101' 'E77' 'F2' 'D38' 'F' 'F G63'\n",
      " 'F E57' 'F E46' 'F G73' 'E121' 'F E69' 'E10' 'G6' 'F38']\n",
      "----------------------------------------\n",
      "Column: embarked\n",
      "Number of unique values: 3\n",
      "Unique values: ['S' 'C' nan 'Q']\n",
      "----------------------------------------\n",
      "Column: boat\n",
      "Number of unique values: 27\n",
      "Unique values: ['2' '11' nan '3' '10' 'D' '4' '9' '6' 'B' '8' 'A' '5' '7' 'C' '14' '5 9'\n",
      " '13' '1' '15' '5 7' '8 10' '12' '16' '13 15 B' 'C D' '15 16' '13 15']\n",
      "----------------------------------------\n",
      "Column: body\n",
      "Number of unique values: 121\n",
      "Unique values: [nan '135' '22' '124' '148' '208' '172' '269' '62' '133' '275' '147' '110'\n",
      " '307' '38' '80' '45' '258' '126' '292' '175' '249' '230' '122' '263'\n",
      " '234' '189' '166' '207' '232' '16' '109' '96' '46' '245' '169' '174' '97'\n",
      " '18' '130' '17' '295' '286' '236' '322' '297' '155' '305' '19' '75' '35'\n",
      " '256' '149' '283' '165' '108' '121' '52' '209' '271' '43' '15' '101'\n",
      " '287' '81' '294' '293' '190' '72' '103' '79' '259' '260' '142' '299'\n",
      " '171' '9' '197' '51' '187' '68' '47' '98' '188' '69' '306' '120' '143'\n",
      " '156' '285' '37' '58' '70' '196' '153' '61' '53' '201' '309' '181' '173'\n",
      " '89' '4' '206' '327' '119' '7' '32' '67' '284' '261' '176' '50' '1' '255'\n",
      " '298' '314' '14' '131' '312' '328' '304']\n",
      "----------------------------------------\n",
      "Column: home.dest\n",
      "Number of unique values: 369\n",
      "Unique values: ['St Louis, MO' 'Montreal, PQ / Chesterville, ON' 'New York, NY'\n",
      " 'Hudson, NY' 'Belfast, NI' 'Bayside, Queens, NY' 'Montevideo, Uruguay'\n",
      " 'Paris, France' nan 'Hessle, Yorks' 'Montreal, PQ' 'Winnipeg, MN'\n",
      " 'San Francisco, CA' 'Dowagiac, MI' 'Stockholm, Sweden / Washington, DC'\n",
      " 'Trenton, NJ' 'Glen Ridge, NJ' 'Youngstown, OH'\n",
      " 'Birkdale, England Cleveland, Ohio' 'London / Winnipeg, MB'\n",
      " 'Cooperstown, NY' 'St Leonards-on-Sea, England Ohio' 'Los Angeles, CA'\n",
      " 'Pomeroy, WA' 'Omaha, NE' 'Philadelphia, PA' 'Denver, CO' 'Belmont, MA'\n",
      " 'Washington, DC' 'Austria-Hungary / Germantown, Philadelphia, PA'\n",
      " 'Germantown, Philadelphia, PA' 'Bryn Mawr, PA'\n",
      " 'Ascot, Berkshire / Rochester, NY' 'Little Onn Hall, Staffs' 'Amenia, ND'\n",
      " 'New York, NY / Ithaca, NY' 'London, England'\n",
      " 'Liverpool, England / Belfast' 'Stoughton, MA' 'Victoria, BC'\n",
      " 'Lakewood, NJ' 'Roachdale, IN' 'Milwaukee, WI' 'Lima, Peru' 'Calgary, AB'\n",
      " 'Deephaven, MN / Cedar Rapids, IA' 'London / Paris'\n",
      " 'Mt Airy, Philadelphia, PA' 'Brookline, MA' 'Brooklyn, NY' 'Winnipeg, MB'\n",
      " 'Westcliff-on-Sea, Essex' 'Zurich, Switzerland' 'Scituate, MA'\n",
      " \"St Anne's-on-Sea, Lancashire\" 'Paris, France / New York, NY'\n",
      " 'Greenwich, CT' 'Kingston, Surrey' 'London / Middlesex' 'Brighton, MA'\n",
      " 'London / Birmingham' 'Chicago, IL' 'Indianapolis, IN'\n",
      " 'New York, NY /  Stamford CT' 'Paris, France New York, NY' 'Liverpool'\n",
      " 'Bennington, VT' 'London' 'Buffalo, NY' 'Southington / Noank, CT'\n",
      " 'Boston, MA' 'Portland, OR' 'Stockholm, Sweden' 'Springfield, MA'\n",
      " 'London / New York, NY' 'Brockton, MA' 'Belgium  Montreal, PQ'\n",
      " 'Vancouver, BC' 'Dorchester, MA' 'East Bridgewater, MA' 'Fond du Lac, WI'\n",
      " 'Green Bay, WI' 'Lexington, MA' 'Isle of Wight, England' 'Providence, RI'\n",
      " '?Havana, Cuba' 'Belfast' 'Surbiton Hill, Surrey' 'Isleworth, England'\n",
      " 'Madrid, Spain' 'Toronto, ON' 'Worcester, MA' 'Rotterdam, Netherlands'\n",
      " 'Paris /  New York, NY' 'Seattle, WA' 'London  Vancouver, BC'\n",
      " 'Haverford, PA / Cooperstown, NY' 'Manchester, England'\n",
      " 'New York, NY / Greenwich CT' 'Duluth, MN' 'Basel, Switzerland'\n",
      " 'New Britain, CT' 'St James, Long Island, NY' 'Huntington, WV'\n",
      " 'Streatham, Surrey' 'Minneapolis, MN' 'Tuxedo Park, NY'\n",
      " 'Wimbledon Park, London / Hayling Island, Hants' 'Newark, NJ'\n",
      " 'Haverford, PA' 'Gallipolis, Ohio / ? Paris / New York' 'Cincinatti, OH'\n",
      " 'Haddenfield, NJ' 'London /  East Orange, NJ' 'Albany, NY'\n",
      " 'Mexico City, Mexico' 'East Orange, NJ' 'England Salt Lake City, Utah'\n",
      " 'Brunswick, ME' 'New York, NY / Briarcliff Manor NY' 'Elkins Park, PA'\n",
      " 'Geneva, Switzerland / Radnor, PA' 'Halifax, NS'\n",
      " 'New York, NY / Washington, DC' 'Russia New York, NY'\n",
      " 'Bryn Mawr, PA, USA' 'Buenos Aires, Argentina / New Jersey, NJ'\n",
      " 'Cornwall, England Houghton, MI' 'Warwick, England' 'West Hoboken, NJ'\n",
      " 'Penzance, Cornwall / Akron, OH' 'Guernsey'\n",
      " 'Bristol, Avon / Jacksonville, FL' 'Plymouth, Dorset / Houghton, MI'\n",
      " 'Jacksonville, FL' 'Norwich / New York, NY' 'England'\n",
      " 'Guntur, India / Benton Harbour, MI' 'Rochester, NY'\n",
      " 'St Ives, Cornwall / Calumet, MI' 'Elmira, NY / Orange, NJ'\n",
      " 'Lake Arthur, Chavez County, NM' 'London / Montreal, PQ'\n",
      " 'Cape Town, South Africa / Seattle, WA' 'Skara, Sweden / Rockford, IL'\n",
      " 'Sittingbourne, England / San Diego, CA' 'Southsea, Hants'\n",
      " 'Bangkok, Thailand / Roseville, IL' 'Mamaroneck, NY' 'Bronx, NY'\n",
      " 'Cornwall / Spokane, WA' 'England / San Francisco, CA'\n",
      " 'Hartford, Huntingdonshire' 'Helsinki, Finland Ashtabula, Ohio'\n",
      " 'London / Fort Byron, NY' 'Bishopstoke, Hants / Fayette Valley, ID'\n",
      " 'Pennsylvania' 'Provo, UT' 'Upper Burma, India Pittsburgh, PA'\n",
      " 'St Ives, Cornwall / Hancock, MI' 'Lyndhurst, England'\n",
      " 'London / Staten Island, NY' 'Portugal / Sau Paulo, Brazil'\n",
      " 'Lucca, Italy / California' 'Guernsey / Elizabeth, NJ'\n",
      " 'New Forest, England' 'Southampton' 'Holley, NY' 'Greenport, NY'\n",
      " 'Barcelona, Spain / Havana, Cuba' 'England / Detroit, MI'\n",
      " 'Goteborg, Sweden / Rockford, IL' 'Oslo, Norway Bayonne, NJ'\n",
      " 'England / Philadelphia, PA' 'Cornwall / Houghton, MI'\n",
      " 'Janjgir, India / Pennsylvania' 'Liverpool / Montreal, PQ'\n",
      " 'Cornwall / Clear Creek, CO' 'Cornwall' 'Cornwall / Camden, NJ'\n",
      " 'West Kensington, London' 'Clevedon, England' 'Auburn, NY' 'Detroit, MI'\n",
      " 'Seattle, WA / Toledo, OH' 'Denmark Hill, Surrey / Chicago'\n",
      " 'Walthamstow, England' 'Ilford, Essex / Winnipeg, MB'\n",
      " 'Somerset / Bernardsville, NJ' 'India / Rapid City, SD'\n",
      " 'West Hampstead, London / Neepawa, MB'\n",
      " 'Kontiolahti, Finland / Detroit, MI' 'Cornwall / Akron, OH'\n",
      " 'Devonport, England' 'England / Sacramento, CA' 'Tokyo, Japan'\n",
      " 'Swindon, England' 'North Evington, England'\n",
      " 'St Ives, Cornwall / Houghton, MI' 'Moscow / Bronx, NY'\n",
      " 'India / Pittsburgh, PA' 'Harrisburg, PA' 'Glasgow / Bangor, ME'\n",
      " 'Sweden / Arlington, NJ' 'Paris / Haiti'\n",
      " 'Berne, Switzerland / Central City, IA' 'London / Chicago, IL'\n",
      " 'Weston-Super-Mare, Somerset' 'Southampton / New York, NY' 'Paris'\n",
      " 'Paris / Montreal, PQ' 'St Austall, Cornwall'\n",
      " 'Weston-Super-Mare / Moose Jaw, SK' 'Sydney, Australia' 'Sarnia, ON'\n",
      " 'England / Bennington, VT' 'Chelsea, London'\n",
      " 'Harrow-on-the-Hill, Middlesex' 'Copenhagen, Denmark'\n",
      " 'Guernsey / Montclair, NJ and/or Toledo, Ohio' 'Frankfort, KY'\n",
      " 'Halesworth, England' 'Cambridge, MA' 'Nice, France'\n",
      " 'Cornwall / Hancock, MI' 'Glasgow' 'Cologne, Germany'\n",
      " 'Folkstone, Kent / New York, NY' 'Middleburg Heights, OH'\n",
      " 'Pondersend, England / New Durham, NJ' 'Spain / Havana, Cuba'\n",
      " 'Hamilton, ON' 'St Andrews, Guernsey' 'Woodford County, KY'\n",
      " 'Gunnislake, England / Butte, MT' 'Ilfracombe, Devon'\n",
      " 'Worcester, England' 'Russia' 'Denmark / New York, NY' 'Milford, NH'\n",
      " 'Plymouth, Devon / Detroit, MI' 'Brighton, Sussex' 'Elizabeth, NJ'\n",
      " 'Spain' 'London, England / Marietta, Ohio and Milwaukee, WI'\n",
      " 'Guernsey / Wilmington, DE' 'Hornsey, England' 'Deer Lodge, MT'\n",
      " 'Finland / Minneapolis, MN' 'Finland / Washington, DC'\n",
      " 'Sault St Marie, ON' 'Catford, Kent / Detroit, MI' 'Columbus, OH'\n",
      " 'Bath, England / Massachusetts' 'Plymouth, England'\n",
      " 'Barre, Co Washington, VT' 'Bristol, England / New Britain, CT'\n",
      " 'Aberdeen / Portland, OR' 'England / Hartford, CT'\n",
      " 'Bromsgrove, England / Montreal, PQ' 'Bournmouth, England'\n",
      " 'Guernsey, England / Edgewood, RI' 'Harrow, England'\n",
      " 'Yoevil, England / Cottage Grove, OR' 'East Providence, RI'\n",
      " 'Norway Los Angeles, CA' 'Perkins County, SD'\n",
      " 'Taalintehdas, Finland Hoboken, NJ' 'Greensburg, PA'\n",
      " 'Asarum, Sweden Brooklyn, NY' 'Bournemouth, England' 'Sweden Akeley, MN'\n",
      " 'London, England Norfolk, VA' 'Syria Fredericksburg, VA'\n",
      " 'England Albion, NY' 'Salo, Finland Astoria, OR' 'Argentina'\n",
      " 'Lower Clapton, Middlesex or Erdington, Birmingham'\n",
      " 'Windsor, England New York, NY' 'Bergen, Norway' 'Sweden Winnipeg, MN'\n",
      " 'Ruotsinphyhtaa, Finland New York, NY' 'Vadsbro, Sweden Ministee, MI'\n",
      " 'Hartford, CT' 'Sweden Chicago, IL' 'Bulgaria Chicago, IL'\n",
      " 'Altdorf, Switzerland' 'Sweden Joliet, IL' 'Sweden  Worcester, MA'\n",
      " 'Sweden Worcester, MA' 'Oskarshamn, Sweden Minneapolis, MN' 'Ottawa, ON'\n",
      " 'Krakoryd, Sweden Bloomington, IL' 'Syria Youngstown, OH'\n",
      " 'Ruotsinphytaa, Finland New York, NY' 'Syria New York, NY'\n",
      " 'London Skanteales, NY' 'Syria Ottawa, ON' 'England New York, NY'\n",
      " 'Krakudden, Sweden Moune, IL' 'Tranvik, Finland New York' 'Syria'\n",
      " 'Hong Kong New York, NY' 'Brennes, Norway New York'\n",
      " 'Stockholm, Sweden New York' 'Syria Kent, ON' 'Ireland Chicago, IL'\n",
      " 'Treherbert, Cardiff, Wales'\n",
      " 'Kingwilliamstown, Co Cork, Ireland Glens Falls, NY'\n",
      " 'Medeltorp, Sweden Chicago, IL' 'Bridgerule, Devon'\n",
      " 'Broomfield, Chelmsford, England' 'Co Cork, Ireland Roxbury, MA'\n",
      " 'Kingwilliamstown, Co Cork, Ireland New York, NY'\n",
      " 'Co Cork, Ireland Charlestown, MA' 'Co Sligo, Ireland New York, NY'\n",
      " 'Croatia' 'Ireland Philadelphia, PA' 'Dagsas, Sweden Fower, MN'\n",
      " 'Goteborg, Sweden Huntley, IL' 'Co Longford, Ireland New York, NY'\n",
      " 'Co Sligo, Ireland Hartford, CT' 'St Denys, Southampton, Hants'\n",
      " 'Ireland New York, NY' 'Greece' 'Portugal' 'London Brooklyn, NY'\n",
      " 'Co Limerick, Ireland Sherbrooke, PQ' 'Ireland Brooklyn, NY' 'Ireland'\n",
      " 'Austria' 'England Brooklyn, NY' 'Merrill, WI'\n",
      " 'Bristol, England Cleveland, OH' 'Bournemouth, England Newark, NJ'\n",
      " 'Austria-Hungary' 'Australia Fingal, ND' 'Norrlot, Sweden Chicago, IL'\n",
      " 'Co Athlone, Ireland New York, NY' 'Stanton, IA'\n",
      " 'West Bromwich, England Pontiac, MI' 'Liverpool, England Bedford, OH'\n",
      " 'Tampico, MT' 'Belgium Detroit, MI' 'Devon, England Wichita, KS'\n",
      " 'Bulgaria Coon Rapids, IA' 'Kilmacowen, Co Sligo, Ireland New York, NY'\n",
      " 'England Oglesby, IL' 'Union Hill, NJ' 'London New York, NY'\n",
      " 'Austria Niagara Falls, NY' 'West Haven, CT' 'Tofta, Sweden Joliet, IL'\n",
      " 'Karberg, Sweden Jerome Junction, AZ' 'Effington Rut, SD' 'Illinois, USA'\n",
      " 'Aughnacliff, Co Longford, Ireland New York, NY' 'Italy Philadelphia, PA'\n",
      " 'Rotherfield, Sussex, England Essex Co, MA'\n",
      " 'Bridgwater, Somerset, England' 'Co Clare, Ireland Washington, DC'\n",
      " 'Strood, Kent, England Detroit, MI'\n",
      " 'Wiltshire, England Niagara Falls, NY' 'Dorking, Surrey, England'\n",
      " 'Foresvik, Norway Portland, ND' 'Waukegan, Chicago, IL'\n",
      " 'Myren, Sweden New York, NY' 'Finland Sudbury, ON'\n",
      " 'Oslo, Norway Cameron, WI' 'Antwerp, Belgium / Stanton, OH']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Task for students: Loop through categorical columns and print the unqiue values of each categorical column\n",
    "for col in data.select_dtypes(include=['object', 'category']).columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Number of unique values: {data[col].nunique()}\")\n",
    "    print(f\"Unique values: {data[col].unique()}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Task for students: retain only the first cabin if more than 1 are available per passenger\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Task for students: extracts the title (Mr, Ms, etc) from the name variable\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Task for students: cast numerical variables as floats\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Task for students: which of these columns would you consider for one-hot encoding? and which ones are useless for the analysis? \n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Task for students: drop unnecessary variables \n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Task for students: save the data set into a titanic.csv file \n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the processed data, find numerical and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'survived' # the target we are predicting\n",
    "\n",
    "# categorical variables\n",
    "vars_num = [c for c in data.columns if data[c].dtypes!='O' and c!=target]\n",
    "print('Number of numerical variables: {}'.format(len(vars_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: find numerical and categorical variables in the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find percentages of missing values in the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first in numerical variables\n",
    "data[vars_num].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students:  Find percentages of missing values in categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: Determine cardinality of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students plot the distribution of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: Separate data into train and test\n",
    "use train_test_split from sklearn to divide train and test set, use 0.2 test and the remaining as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "#### ‚úÖ Task for students: Extract only the letter (and drop the number) from the variable Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in Missing data in numerical variables:\n",
    "\n",
    "- Add a binary missing indicator\n",
    "- Fill NA in original variable with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing indicator for age variable\n",
    "X_train['age'+'_NA'] = np.where(X_train['age'].isnull(), 1, 0)\n",
    "X_test['age'+'_NA'] = np.where(X_test['age'].isnull(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN by median you extracted from the training data\n",
    "median_val = X_train['age'].median()\n",
    "\n",
    "X_train['age'] = X_train['age'].fillna(median_val)\n",
    "X_test['age'] = X_test['age'].fillna(median_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: add missing indicator for fare variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: replace NaN by median you extracted from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the missing values were correctly replaced\n",
    "X_train[['age', 'fare']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: Replace Missing data in categorical variables with the string **Missing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check is there are any missing data in any of the variables in both test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: Remove rare labels in categorical variables\n",
    "- print the different value counts for each of the categories in the cabin variable, what do you notice\n",
    "- use the df[column].value_counts(normalize=True) to find the percentage of each category for each variable\n",
    "- remove labels present in less than 5 % of the passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the cardinality of categorical variables\n",
    "X_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the cardinality of categorical variables\n",
    "X_test[vars_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ‚úÖ Task for students: Perform one hot encoding of categorical variables into k-1 binary variables\n",
    "\n",
    "- k-1, means that if the variable contains 9 different categories, we create 8 different binary variables\n",
    "- use OneHotEncoder from sklearn. The encoder will output a numpy array. You should use encoder.get_feature_names_out() to recreate a new dataframe\n",
    "- remember to fit the encoder to the training data and to use it on the test data\n",
    "- Remember to drop the original categorical variable (the one with the strings) after the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure both dataframes have the same columns with the same order (important for scaling)\n",
    "X_train.columns==X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: Scale the variables\n",
    "-  Use the standard scaler from Scikit-learn\n",
    "-  make sure that you have the same order of variables in both train and test data\n",
    "-  dont forget to use the same scaling parameters from the train data for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: Train a Logistic Regression model from sklearn\n",
    "\n",
    "- use sklearn to build a LogisticRegression model\n",
    "- Set the regularization parameter to 0.0005\n",
    "- Set the seed to 0 for reproducibility\n",
    "- remember to train the model by using model.fit after you initialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions and evaluate model performance\n",
    "Determine:\n",
    "- accuracy\n",
    "- roc-auc\n",
    "on both training and test data. Try different options (weighted vs. micro vs. macro) and try to understand the differences\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate the models \n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "\n",
    "# make predictions for train set\n",
    "class_ = model.predict(X_train)\n",
    "pred = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
    "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Task for students: make predictions for test set and print accuracy and roc-auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it! Well done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
